---
title: "In-class Exercise 5: Geographically Weighted Logistic Regression (GWLR) and Application"
editor: visual
---

# Overview

In this in-class exercise, I utilized the following Geographical Weighted Logistic Regression (GWLR) algorithm:

-   Weighting functions (kernel)

-   Weighting schemes

-   Bandwidth

# Getting Started

## Setting the Scene

-   To build an explanatory model to discover factor affecting water point status in Osun State, Nigeria (one of the LGAs with the highest percentage of non-functional waterpoints, over 40% which is more than the national average)

-   ﻿﻿Study area: Orun State, Nigeria

-   ﻿﻿Data sets:

    -   ﻿﻿**Osun.rds** contains LGAs boundaries of sun State. It is in sf polygon data frame, and

    -   ﻿﻿**Osun\_ wp_sf.rds** contained water points within Osun State. It is in sf point data frame.

## **Model Variables**

-   ﻿﻿**Dependent** variable: Water point status (i.e. functional/non-functional)

-   ﻿﻿**Independent** variables:

    -   ﻿﻿distance_to_primary_road,

    -   ﻿﻿distance_to_secondary_road,

    -   ﻿distance_to_tertiary_road,

    -   ﻿distance_to_city,

    -   ﻿distance_to_town,

    -   ﻿﻿water_point_population,

    -   ﻿﻿local_population_1km,

    -   ﻿﻿usage_capacity,

    -   ﻿﻿is_urban,

    -   ﻿﻿water source clean

Note: All variables are continuous, **except** for the last 3 variables (categorical).

## Setting the Analytical Tools

The code chunk below installs and loads the following R packages:

-   sf

-   tidyverse

-   funModeling

-   corrplot

-   ggpubr

-   sf

-   spdep

-   GWmodel

-   tmap

New packages:

-   [`caret`](http://cran.r-project.org/web/packages/caret/index.html) (short for **C**lassification **A**nd **RE**gression **T**raining) is a set of functions that attempt to streamline the process for creating predictive models. The package contains tools for: data splitting, pre-processing, feature selection, model tuning using resampling, variable importance estimation etc.
-   [skimr](https://cran.r-project.org/web/packages/skimr/vignettes/skimr.html) provides summary statistics about variables in data frames, tibbles, data tables and factors. It is opinionated in its defaults, but easy to modify. In base R, the most similar functions are `summary()` for factors and data frames and `fivenum()` for numeric factors.
-   [blorr](https://cran.r-project.org/web/packages/blorr/vignettes/introduction.html) offers tools for building and validating binary logistic regression models.

```{r}
pacman::p_load(sf, tidyverse, funModeling, blorr, corrplot, ggpubr, spdep, GWmodel, tmap, skimr, caret)
```

## Importing the Analytical data

```{r}
Osun <- read_rds("rds/Osun.rds")
Osun_wp_sf <- read_rds("rds/Osun_wp_sf.rds")
```

# Exploratory Data Analysis (EDA)

The code chunk below uses freq() to see the breakdown of the 'status' column by functional and non-functional waterpoints, represented by 'True' and 'False' respectively.

```{r}
Osun_wp_sf %>%
  freq(input = 'status')
```

## Importing Nigeria LGA level boundary

The code chunk below plots the status of the waterpoints on the Nigeria LGA level map:

```{r}
tmap_mode("view")
tm_shape(Osun)+
#  tmap_options(check.and.fix = TRUE)+
  tm_polygons(alpha=0.4)+
tm_shape(Osun_wp_sf)+
  tm_dots(col="status",
          alpha = 0.6)+
  tm_view(set.zoom.limits = c(9,12))
```

**Observation:** From the map above, we can see that both functional and non-functional waterpoints are quite evenly scattered across LGAs in Nigeria. To understand the logical relationship between status of waterpoints and the LGAs, we can do further analysis on different data variables available.

## Summary Statistics using skimr

The code chunk below generates summary statistics with skim() of the skimr package:

```{r}
Osun_wp_sf %>%
  skim()
```

**Observation:** From the results above, we can see that install_year and fecal_coliform_value have excessive number of missing values, thus should not be used in our analysis to prevent data loss.

-   Note to think of **extent of data loss:** number of loss in comparison to total number of data points

The code chunk below is to exclude all missing values + change data type into factor:

```{r}
Osun_wp_sf_clean <- Osun_wp_sf %>%
  filter_at(vars(status,
                 distance_to_primary_road,
                 distance_to_secondary_road,
                 distance_to_tertiary_road,
                 distance_to_city,
                 distance_to_town,
                 water_point_population,
                 local_population_1km,
                 usage_capacity,
                 is_urban,
                 water_source_clean),
            all_vars(!is.na(.))) %>%
  mutate(usage_capacity = as.factor(usage_capacity))
```

Note: **usage_capacity** is no longer [numeric (assume to be continuous)]{.underline} in nature and has become a factor. **Osun_wp_sf_clean dataset** has 4 less records than Osun_wp_sf.

# Correlation Analysis

The code chunk below drops irrelevant data columns:

```{r}
Osun_wp <- Osun_wp_sf_clean %>%
  select(c(7,35:39,42:43,46:47,57)) %>%
  st_set_geometry(NULL)
# OR st_drop_geometry()
```

The code chunk below takes all numerical fields to do correlation:

```{r}
cluster_vars.cor = cor(
  Osun_wp[,2:7])
corrplot.mixed(cluster_vars.cor,
               lower = "ellipse",
               upper = "number",
               tl.pos = "lt",
               diag = "l",
               tl.col = "black")
```

**Observation:** From the results above, there are no variables that are highly correlated (\>=0.8). Thus, there is no sign of multi-collinearity between these variables.

# Building a Logistic Regression Model

glm of R is used to calibrate a logistic regression for the water point status.

```{r}
model <- glm(status ~ distance_to_primary_road +
               distance_to_secondary_road +
               distance_to_tertiary_road +
               distance_to_city + 
               distance_to_town +
               is_urban +
               usage_capacity + 
               water_source_clean +
               water_point_population +
               local_population_1km,
             data = Osun_wp_sf_clean,
             family = binomial(link = "logit"))
```

Instead of using a typical R report, blr_regress() of [blorr](https://cran.r-project.org/web/packages/blorr/vignettes/introduction.html) package is used.

```{r}
blr_regress(model)
```

From the report above, we can exclude the **distance_to_primary_road** and **distance_to_secondary_road** as their p-value \> 0.05, so we cannot reject null hypothesis and the test result is not statistically significant.

## Model Assessment of Non-Geographically Weighted Logistic Regression Model

![](images/paste-7DA5BF78.png){width="313"}

The **validity of a cut-off** (e.g. 0.5) is measured using sensitivity, specificity and accuracy.

-   **Sensitivity:** The % of correctly classified events out of all events = TP / (TP + FN)

-   **Specificity:** The % of correctly classified non-events out of all non-events = TN / (TN + FP)

-   **Accuracy:** The % of correctly classified events out of all events = (TP + TN) / (TP + FP + TN + FN)

Using the code chunk below, we can get the confusion matrix:

```{r}
blr_confusion_matrix(model, cutoff = 0.5)
```

**Observation:** From the results, we can see that the model gives us an accuracy of 67.4%, which is better than guessing (50%).

The sensitivity and specificity are 72.1% and 61.5% respectively, which shows that the true positives are slightly higher than the true negative prediction rates.

# Building Geographically Weighted Logistic Regression

## Converting from sf to sp data frame

The code chunk below converts all variables laid out in the Model Variables section from sf dataframe to sp dataframe:

```{r}
Osun_wp_sp <- Osun_wp_sf_clean %>%
  select(c(status,
           distance_to_primary_road,
           distance_to_secondary_road,
           distance_to_tertiary_road,
           distance_to_city,
           distance_to_town,
           water_point_population,
           local_population_1km,
           usage_capacity,
           is_urban,
           water_source_clean)) %>%
  as_Spatial()
Osun_wp_sp
```

## Building fixed bandwidth GWR model

The code chunk below computes the distance matrix using ggwr() of the sp package:

```{r}
bw.fixed <- bw.ggwr(status ~
distance_to_primary_road +
               distance_to_secondary_road +
               distance_to_tertiary_road +
               distance_to_city + 
               distance_to_town +
               is_urban +
               usage_capacity + 
               water_source_clean +
               water_point_population +
               local_population_1km,
              data = Osun_wp_sp,
              family = "binomial",
              approach = "AIC",
              kernel = "gaussian",
              adaptive = FALSE,
              longlat = FALSE)
```

```{r}
bw.fixed
```

We need to remove 2 statistically insignificant data columns (p-value \> 0.05): ***distance_to_primary_road** and **distance_to_secondary_road***

```{r}
gwlr.fixed <- ggwr.basic(status ~
                           distance_to_tertiary_road +
                           distance_to_city +
                           distance_to_town +
                           is_urban +
                           usage_capacity +
                           water_source_clean +
                           water_point_population +
                           local_population_1km,
                         data = Osun_wp_sp,
                         bw = bw.fixed,
                         family = "binomial",
                         kernel = "gaussian",
                         adaptive = FALSE,
                         longlat = FALSE)
```

```{r}
gwlr.fixed
```

From the results above, AIC reduced from 5708.9 (non-geographically weighted regression model) to 4500.0 (geographically weighted regression model), thus there was an improvement in the regression model.

## Model Assessment of Geographically Weighted Logistic Regression Model

### Converting SDF into sf data.frame

To assess the performance of gwlr, firslty, we will convert the SDF object in as dataframe by using the code chunk below:

```{r}
gwr.fixed <- as.data.frame(gwlr.fixed$SDF)
```

Next, we will be labelling yhat values greater or equal to 0.5 into 1 and else 0. The result of the logic comparison operation will be saved into a field called *most*.

```{r}
gwr.fixed <- gwr.fixed %>%
  mutate(most = ifelse(
    gwr.fixed$yhat >= 0.5,T,F))
```

### Model Assessment

Originally, y data column is logi data while yhat is numerical data. Thus, we need to use as.factor() to convert both columns to factors for comparison.

```{r}
gwr.fixed$y <-as.factor(gwr.fixed$y)
gwr.fixed$most <- as.factor(gwr.fixed$most)
CM <- confusionMatrix(data=gwr.fixed$most, reference = gwr.fixed$y)
CM
```

**Observation:** From the results above, we can see improvement in the accuracy (from 67.4% to 86.9%), as a result of improvements in both sensitivity (from 72.1% to 84.8%) and specificity (from 61.5% to 88.6%).

Thus, **geographically weighted is a better model**, given the improvement in accuracy and increase in true negative (i.e. specificity) which allows for better explanation of non-functional waterpoint. To better manage the waterpoints, we need to look a **local strategy for specific LGAs** (in this case, we are looking at Osun).

## Visualising gwLR

```{r}
Osun_wp_sf_selected <- Osun_wp_sf_clean %>%
  select(c(ADM2_EN, ADM2_PCODE,
           ADM1_EN, ADM1_PCODE,
           status))
```

```{r}
gwr_sf.fixed <- cbind(Osun_wp_sf_selected, gwr.fixed)
```

### Visualising coefficient estimates

The code chunks below is used to create an interactive point symbol map.

```{r}
tmap_mode("view")
prob_T <- tm_shape(Osun)+
  tm_polygons(alpha = 0.1)+

tm_shape(gwr_sf.fixed) +
  tm_dots(col = "yhat",
          border.col = "gray60",
          border.lwd = 1)+
  tm_view(set.zoom.limits = c(8,14))

prob_T
```

The code chunk below converts the t_score of a variable to its equivalent p-value to retrieve the statistically significant data rows:

```{r}
t_score <- gwr_sf.fixed$distance_to_tertiary_road_SE
pval_distance_tertiary = 2*pt(q = t_score, df = 4755, lower.tail = FALSE)
gwr_sf.fixed_SE <- cbind(gwr_sf.fixed, pval_distance_tertiary)
```

```{r}
tmap_mode("view")

tertiary_TV <- tm_shape(Osun) +
  tm_polygons(alpha = 0.1) +
  tm_shape(gwr_sf.fixed) +
  tm_dots(col = "distance_to_tertiary_road_TV",
          border.col = "gray60",
          border.lwd = 1) +
  tm_view(set.zoom.limits = c(8,14))

tertiary_SE <- tm_shape(Osun)+
    tm_polygons(alpha=0.1)+
    tm_shape(gwr_sf.fixed_SE)+
    tm_dots(col="distance_to_tertiary_road_SE",
            border.col="gray60",
            border.lwd = 1)+
    tm_view(set.zoom.limits = c(8,14))

tmap_arrange(tertiary_SE, tertiary_TV, asp=1, ncol=2, sync=TRUE)
```

# Conclusion

**Geographically weighted logistic regression model is a better model than non-geographically weighted logistic regression model**, given higher accuracy, sensitivity and specificity.
